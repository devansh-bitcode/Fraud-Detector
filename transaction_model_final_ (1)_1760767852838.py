# -*- coding: utf-8 -*-
"""Transaction model final .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VUfbL_il_LKc13ONV8aJO-JYNg3tjvQl
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, precision_recall_curve, roc_auc_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt

# Load synthetic dataset
df = pd.read_csv("synthetic_transactions.csv")
df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

# -----------------------------
# Feature Engineering
# -----------------------------
df['hour'] = df['timestamp'].dt.hour
df['is_night'] = df['hour'].apply(lambda x: 1 if x < 6 or x > 20 else 0)
df['is_weekend'] = df['timestamp'].dt.weekday.apply(lambda x: 1 if x >= 5 else 0)
df['log_amount'] = np.log1p(df['amount'])

df['avg_user_spend'] = df.groupby('user_id')['amount'].transform('mean')
df['user_spend_dev'] = df['amount'] - df['avg_user_spend']

fraud_rate_map = df.groupby('merchant_id')['is_fraud'].mean()
df['merchant_fraud_rate'] = df['merchant_id'].map(fraud_rate_map).fillna(0)

df = df.sort_values(['user_id', 'timestamp'])
df['user_txn_gap'] = df.groupby('user_id')['timestamp'].diff().dt.total_seconds().fillna(3600)
df['velocity_1h'] = (df['user_txn_gap'] < 3600).astype(int)

iso = IsolationForest(random_state=42, n_jobs=-1)
df['anomaly_score'] = iso.fit_predict(df[['log_amount', 'user_spend_dev']])

df = pd.get_dummies(df, columns=['transaction_type'])

# -----------------------------
# Features and Target
# -----------------------------
feature_cols = [
    'log_amount', 'user_spend_dev', 'hour', 'is_night', 'is_weekend',
    'merchant_fraud_rate', 'velocity_1h', 'anomaly_score'
] + [col for col in df.columns if col.startswith('transaction_type_')]

X = df[feature_cols]
y = df['is_fraud']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -----------------------------
# Faster XGBoost Training
# -----------------------------
scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]

xgb_model = XGBClassifier(
    n_estimators=150,        # fewer trees
    max_depth=5,
    learning_rate=0.05,      # faster learning
    gamma=0.2,
    min_child_weight=5,
    subsample=0.85,
    colsample_bytree=0.85,
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    use_label_encoder=False,
    eval_metric='logloss',
    n_jobs=-1
)
xgb_model.fit(X_train_scaled, y_train)

# -----------------------------
# Evaluation
# -----------------------------
y_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]
precision, recall, thresholds = precision_recall_curve(y_test, y_proba)

desired_precision_range = (0.4, 0.6)
valid_indices = np.where((precision[:-1] >= desired_precision_range[0]) &
                         (precision[:-1] <= desired_precision_range[1]))[0]

if len(valid_indices) == 0:
    optimal_threshold = 0.5
else:
    f1_scores = 2 * (precision[valid_indices] * recall[valid_indices]) / \
                (precision[valid_indices] + recall[valid_indices] + 1e-8)
    best_index = valid_indices[np.argmax(f1_scores)]
    optimal_threshold = thresholds[best_index]

y_pred = (y_proba >= optimal_threshold).astype(int)

print("Classification Report:\n", classification_report(y_test, y_pred, digits=4))
print(f"ROC-AUC Score: {roc_auc_score(y_test, y_proba):.4f}")
print(f"Accuracy: {(y_pred == y_test).mean():.4f}")
print(f"Optimal threshold: {optimal_threshold:.3f}")

# Plot Precision-Recall Curve
plt.figure(figsize=(8, 6))
plt.plot(thresholds, precision[:-1], label='Precision')
plt.plot(thresholds, recall[:-1], label='Recall')
plt.axhline(0.4, color='red', linestyle='--', label='Precision Lower Bound')
plt.axhline(0.6, color='green', linestyle='--', label='Precision Upper Bound')
plt.xlabel('Threshold')
plt.ylabel('Score')
plt.title('Precision-Recall Curve')
plt.legend()
plt.grid(True)
plt.show()

# -----------------------------
# Suspicious Transactions
# -----------------------------
suspect_transactions = df.iloc[y_test.index].copy()
suspect_transactions['fraud_proba'] = y_proba
suspect_transactions['fraud_pred'] = y_pred

# Filter only predicted frauds
suspicious = suspect_transactions[suspect_transactions['fraud_pred'] == 1]

# Select useful columns
suspicious_list = suspicious[[
    'transaction_id', 'user_id', 'merchant_id', 'amount',
    'timestamp', 'fraud_proba', 'fraud_pred'
]].sort_values(by='fraud_proba', ascending=False)

print("\nSuspicious Transactions:\n")
print(suspicious_list.head(20))  # show top 20

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Fraud','Fraud'], yticklabels=['Not Fraud','Fraud'])
plt.title("Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()

importances = xgb_model.feature_importances_
feat_imp = pd.DataFrame({'feature': X.columns, 'importance': importances})
feat_imp = feat_imp.sort_values('importance', ascending=False)

plt.figure(figsize=(8,6))
plt.barh(feat_imp['feature'], feat_imp['importance'])
plt.gca().invert_yaxis()
plt.title("Feature Importance (XGBoost)")
plt.show()

detected_frauds = suspicious_list['amount'].sum()
print(f"Total fraud amount detected: {detected_frauds:.2f}")
print(f"Fraud transactions flagged: {len(suspicious_list)} / {sum(y_test)} actual frauds")